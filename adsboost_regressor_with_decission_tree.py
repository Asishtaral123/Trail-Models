# -*- coding: utf-8 -*-
"""AdsBoost regressor with Decission Tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mYnDRtPgRETrc3CAj_m9_YltYMvyusHv
"""

# Step 1: Import necessary libraries
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd

# Step 2: Load the dataset
data = pd.read_csv("C:\\Users\\asish\\Documents\\soil-data (3).csv")

data.drop(columns=['Unnamed: 0'], inplace=True)

# encode categorical variables using label encoding
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
data['Crop_Type'] = label_encoder.fit_transform(data['Crop_Type'])
data['Fertilizer_Type'] = label_encoder.fit_transform(data['Fertilizer_Type'])

data.head(5)

# Split the dataset into features (X) and target variables (y)
X = data.drop(columns=['Crop_Type', 'Fertilizer_Type'])  # Features
# Define y as the target variable containing both "Crop_Type" and "Fertilizer_Type"
y = data[['Crop_Type', 'Fertilizer_Type']]
y_crop = data['Crop_Type']  # Target variable for Crop_Type
y_fertilizer = data['Fertilizer_Type']  # Target variable for Fertilizer_Type

# Split the dataset into training and testing sets for crop_type
X_train_crop, X_test_crop, y_train_crop, y_test_crop = train_test_split(X, y['Crop_Type'], test_size=0.2, random_state=42)

# Split the dataset into training and testing sets for fertilizer_type
X_train_fertilizer, X_test_fertilizer, y_train_fertilizer, y_test_fertilizer = train_test_split(X, y['Fertilizer_Type'], test_size=0.2, random_state=42)

# Create AdaBoostRegressor model for Crop_Type
# Initialize AdaBoostRegressor without specifying base_estimator
ada_clf_crop = AdaBoostRegressor(n_estimators=50, learning_rate=1.0, random_state=42)

# Set base_estimator separately
ada_clf_crop.base_estimator_ = DecisionTreeRegressor()
ada_clf_crop.fit(X_train_crop, y_train_crop)

# Create AdaBoostRegressor model for Fertilizer_Type
ada_clf_fertilizer = AdaBoostRegressor(n_estimators=50, learning_rate=1.0, random_state=42)
# set base-estimator separately
ada_clf_fertilizer.base_estimator_ = DecisionTreeRegressor()
ada_clf_fertilizer.fit(X_train_fertilizer, y_train_fertilizer)


from sklearn.model_selection import GridSearchCV

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 150],  # Number of estimators (decision trees) in the ensemble
    'learning_rate': [0.1, 0.5, 1.0]  # Learning rate
}

# Hyperparameter tuning for Crop_Type
grid_search_crop = GridSearchCV(ada_clf_crop, param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search_crop.fit(X_train_crop, y_train_crop)

# Hyperparameter tuning for Fertilizer_Type
grid_search_fertilizer = GridSearchCV(ada_clf_fertilizer, param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search_fertilizer.fit(X_train_fertilizer, y_train_fertilizer)

# Get the best hyperparameters for each model
best_params_crop = grid_search_crop.best_params_
best_params_fertilizer = grid_search_fertilizer.best_params_

print("Best hyperparameters for Crop_Type:", best_params_crop)
print("Best hyperparameters for Fertilizer_Type:", best_params_fertilizer)

# Retrain the model for Crop_Type with the best hyperparameters
# Instantiate AdaBoostRegressor without specifying base_estimator
best_ada_clf_crop = AdaBoostRegressor(n_estimators=best_params_crop['n_estimators'],
                                      learning_rate=best_params_crop['learning_rate'],
                                      random_state=42)
best_ada_clf_crop.fit(X_train_crop, y_train_crop)

# Retrain the model for Fertilizer_Type with the best hyperparameters
best_ada_clf_fertilizer = AdaBoostRegressor(n_estimators=best_params_fertilizer['n_estimators'],
                                            learning_rate=best_params_fertilizer['learning_rate'],
                                            random_state=42)
best_ada_clf_fertilizer.fit(X_train_fertilizer, y_train_fertilizer)


# Train the model for Crop_Type
ada_clf_crop.fit(X_train_crop, y_train_crop)

# Train the model for Fertilizer_Type
ada_clf_fertilizer.fit(X_train_fertilizer, y_train_fertilizer)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Predictions for Crop_Type
crop_predictions = ada_clf_crop.predict(X_test_crop)

# Calculate evaluation metrics for Crop_Type
crop_mae = mean_absolute_error(y_test_crop, crop_predictions)
crop_mse = mean_squared_error(y_test_crop, crop_predictions)
crop_r2 = r2_score(y_test_crop, crop_predictions)

print("Crop_Type evaluation metrics:")
print("Mean Absolute Error:", crop_mae)
print("Mean Squared Error:", crop_mse)
print("R-squared:", crop_r2)

# Predictions for Fertilizer_Type
fertilizer_predictions = ada_clf_fertilizer.predict(X_test_fertilizer)

# Calculate evaluation metrics for Fertilizer_Type
fertilizer_mae = mean_absolute_error(y_test_fertilizer, fertilizer_predictions)
fertilizer_mse = mean_squared_error(y_test_fertilizer, fertilizer_predictions)
fertilizer_r2 = r2_score(y_test_fertilizer, fertilizer_predictions)

print("\nFertilizer_Type evaluation metrics:")
print("Mean Absolute Error:", fertilizer_mae)
print("Mean Squared Error:", fertilizer_mse)
print("R-squared:", fertilizer_r2)

# Define a threshold for accuracy calculation
threshold = 0.5
# Calculate accuracy for Crop_Type
crop_accuracy = sum(abs(crop_predictions - y_test_crop) < threshold) / len(y_test_crop)

# Calculate accuracy for Fertilizer_Type
fertilizer_accuracy = sum(abs(fertilizer_predictions - y_test_fertilizer) < threshold) / len(y_test_fertilizer)

print("Crop_Type Accuracy:", crop_accuracy)
print("Fertilizer_Type Accuracy:", fertilizer_accuracy)